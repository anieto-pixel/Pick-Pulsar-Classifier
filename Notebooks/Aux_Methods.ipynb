{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b7e3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA CLEANING METHODS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e621c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "#Takes a Panda df and the keyword for a column.\n",
    "#If set is not balanced, balances it. Prints informative message.\n",
    "\n",
    "def get_balanced_set_random(df, class_key):\n",
    "\n",
    "    counts = df[class_key].value_counts()\n",
    "\n",
    "    if counts.min() < counts.max() * 0.55:\n",
    "        y = df[class_key]\n",
    "        x = df.drop(class_key, axis=1)\n",
    "\n",
    "        x, y = RandomUnderSampler(random_state=0).fit_resample(x, y)\n",
    "        df.loc[:, class_key] = y\n",
    "        df = df.dropna(axis=0)\n",
    "\n",
    "        print(\"The dataset has been balanced through random undersampling.\")\n",
    "    else:\n",
    "        print(\"The set did not require balancing.\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Receives Panda Dataframe, and an optional flag. \n",
    "# Prepares dataset for training algorithms\n",
    "# If autobalance=True, balances the dataset according to the last column\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "def prepare_data(df, autobalance=False):\n",
    "\n",
    "    keys = df.keys()\n",
    "    class_key = keys[len(keys) - 1]\n",
    "\n",
    "    df.drop_duplicates(subset=None, keep=\"first\", inplace=True)\n",
    "    df.dropna(axis=0, how=\"any\", inplace=True)\n",
    "\n",
    "    if autobalance:\n",
    "        df = get_balanced_set_random(df, class_key)\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        MinMaxScaler().fit(df).transform(df), columns=keys\n",
    "    )\n",
    "\n",
    "    print(f\"The final dataset contains {len(df[keys[0]])} samples\")\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7aade640",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA VISUALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26aba81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def density_plot(df, gen_title):\n",
    "\n",
    "    features = df.copy().iloc[:, 0:8]\n",
    "    fig = plt.figure(figsize=(11, 5))\n",
    "\n",
    "    j = 0\n",
    "    for feature in features.keys():\n",
    "\n",
    "        plt.subplot(2, 4, j + 1)\n",
    "        plt.subplots_adjust(top=0.85, bottom=0.01, hspace=0.5, wspace=0.4)\n",
    "        sns.kdeplot(data=df, x=feature, hue=class_key, fill=True, common_norm=False)\n",
    "\n",
    "        plt.title(feature)\n",
    "        plt.axhline(\n",
    "            df[feature].mean(),\n",
    "            linestyle=\"dashed\",\n",
    "             label =\"Mean value = \" + str(round(df[feature].mean(), 2)),\n",
    "        )\n",
    "        j = j + 1\n",
    "\n",
    "    #plt.savefig(f\"{gen_title}.jpg\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def strip_plot(df, gen_title):\n",
    "\n",
    "    features = df.copy().iloc[:, 0:8]\n",
    "    fig = plt.figure(figsize=(11, 5))\n",
    "\n",
    "    j = 0\n",
    "    for feature in features:\n",
    "\n",
    "        plt.subplot(2, 4, j + 1)\n",
    "        plt.subplots_adjust(top=0.85, bottom=0.01, hspace=0.5, wspace=0.4)\n",
    "        sns.stripplot(data=df, x=df[class_key], y=df[feature], hue=class_key)\n",
    "\n",
    "        plt.title(feature)\n",
    "        plt.axhline(\n",
    "            df[feature].mean(),\n",
    "            linestyle=\"dashed\",\n",
    "             label =\"Mean value = \" + str(round(df[feature].mean(), 2)),\n",
    "        )\n",
    "        plt.legend(loc=\"best\")\n",
    "        j = j + 1\n",
    "\n",
    "    #plt.savefig(f\"{gen_title}.jpg\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def violin_plot(df, gen_title):\n",
    "\n",
    "    features = df.copy().iloc[:, 0:8]\n",
    "    fig = plt.figure(figsize=(11, 5))\n",
    "\n",
    "    j = 0\n",
    "    for feature in features:\n",
    "\n",
    "        plt.subplot(2, 4, j + 1)\n",
    "        plt.subplots_adjust(top=0.85, bottom=0.01, hspace=0.5, wspace=0.4)\n",
    "        sns.violinplot(x=df[class_key], y=df[feature])\n",
    "\n",
    "        plt.title(feature)\n",
    "        plt.axhline(\n",
    "            df[feature].mean(),\n",
    "            linestyle=\"dashed\",\n",
    "            label =\"Mean value = \" + str(round(df[feature].mean(), 2)),\n",
    "        )\n",
    "        plt.legend(loc=\"best\")\n",
    "        j = j + 1\n",
    "\n",
    "    #plt.savefig(f\"{gen_title}.jpg\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f44a4597",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA BALANCING METHODS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "77e763f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Undersampling method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c1a1ae59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accepts a sklearn undersampler, a Pandas df, and a column's name\n",
    "# Appliers sampler to the dataframe once, based on column's name\n",
    "# Returns dataframe\n",
    "\n",
    "\n",
    "def single_run_undersampling(sampler, df, class_key):\n",
    "\n",
    "    label = df[class_key]\n",
    "    feats = df.drop(class_key, axis=1)\n",
    "\n",
    "    feats, label = sampler.fit_resample(feats, label)\n",
    "\n",
    "    df.loc[:, class_key] = label\n",
    "    df = df.dropna(axis=0)\n",
    "\n",
    "    return df #df.dropna()\n",
    "\n",
    "\n",
    "# Accepts a sklearn undersampler, a Pandas df, and a column's name\n",
    "# Recursively appliers sampler to the dataframe until condition is met\n",
    "# Returns dataframe\n",
    "\n",
    "\n",
    "def get_balanced_set_undersampling(sampler, df, class_key):\n",
    " \n",
    "    counts = df[class_key].value_counts()\n",
    "    imbalance_ratio = abs(counts.min() - counts.max()) / (counts.min() + counts.max())\n",
    "    accepted_imbalance_ratio = 0.20\n",
    "\n",
    "    if imbalance_ratio > accepted_imbalance_ratio:\n",
    "\n",
    "        new_df = single_run_undersampling(sampler, df.copy(), class_key)\n",
    "        new_counts = new_df[class_key].value_counts()\n",
    "\n",
    "        if new_counts.max() == new_counts.min():\n",
    "            return new_df\n",
    "        if (\n",
    "            counts.min() >= new_counts.max() * (1 + accepted_imbalance_ratio)\n",
    "            or new_counts.max() == counts.min()\n",
    "        ):\n",
    "            return df\n",
    "\n",
    "        df = get_balanced_set_undersampling(sampler, new_df, class_key)\n",
    "        return df\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a25e032c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accepts a sklearn sampler, a Pandas df, and a column's name\n",
    "# Balances by applying oversampler\n",
    "# Returns panda dataframe\n",
    "\n",
    "\n",
    "def get_balanced_set_oversampling(sampler,df, class_key):# change name\n",
    "    \n",
    "    y_bal=df[class_key]\n",
    "    X_bal=df.drop(class_key, axis=1)\n",
    "    X_bal, y_bal = sampler.fit_resample(X_bal, y_bal)\n",
    "        \n",
    "    X_bal.loc[:, class_key] = y_bal\n",
    "    df=pd.DataFrame(X_bal, columns=keys)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "01ff86c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PERFORMANCE VISUALIZATION METHODS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db1f8d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Accepts list of values v as returned by cross_classifier, and a name\n",
    "# Shows a plot of the Confussion Matrix with a title\n",
    "\n",
    "\n",
    "def my_cross_confussion_matrix(values, sampler_name):\n",
    "\n",
    "    name_graph_sampler = f\"Best result for sampler {sampler_name}.\"\n",
    "    name_graph_classifier = f\"From {values[1]} with parameter {values[2]}\"\n",
    "    name_graph = name_graph_sampler + name_graph_classifier\n",
    "\n",
    "    cmd = ConfusionMatrixDisplay(values[0], display_labels=[\"false pulsar\", \"pulsar\"])\n",
    "    cmd.plot()\n",
    "\n",
    "    cmd.ax_.set(title=name_graph, xlabel=\"Predicted\", ylabel=\"Actual\")\n",
    "    #    plt.savefig(f'{name_graph}.jpg')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fc26b047",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CROSS VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b0acb849",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performance comparison "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb99f788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accepts two Pandas df, dforiginal dataframe, df_bal balanced version of df\n",
    "# Obtains the elements that were deleted from df to create df_bal\n",
    "# Returns the atributes and labels of those objects as two ordered arrays\n",
    "\n",
    "\n",
    "def calculate_pure_test_values(df, df_bal):\n",
    "\n",
    "    x_pure_test = None\n",
    "    y_pure_test = None\n",
    "\n",
    "    if df is not None:\n",
    "        df_pure_test = pd.concat([df.copy(), df_bal.copy()])\n",
    "        df_pure_test.drop_duplicates(subset=None, keep=False, inplace=True)\n",
    "        y_pure_test = df_pure_test[class_key].to_numpy()\n",
    "        x_pure_test = df_pure_test.drop(class_key, axis=1).to_numpy()\n",
    "\n",
    "    return x_pure_test, y_pure_test\n",
    "\n",
    "#RETURN HEREEEE\n",
    "# Accepts a 2D array, a 1D array of objects, two arrays for extra test cases, an estimator and a boolean flag\n",
    "#Calculates the chaos matrix for each prediction run by cross_ \n",
    "#Returns the best one according to our scoring system and the corresponding confussion matrix\n",
    "def cm_all_runs_crosval(x, y, x_pt, y_pt,estimators,indices_test, flag):\n",
    "    \n",
    "    cumulative_y_test=np.array([])\n",
    "    cumulative_y_predict=np.array([])\n",
    "    \n",
    "    for n in range(len(estimators)):\n",
    "        \n",
    "        x_test=np.take(x, indices_test[n],axis=0)\n",
    "        y_test=np.take(y, indices_test[n],axis=0)\n",
    "        \n",
    "        if((x_pt is not None) and (y_pt is not None)):\n",
    "            \n",
    "            x_test=np.concatenate((x_test, x_pt), axis=0)\n",
    "            y_test=np.concatenate((y_test, y_pt), axis=0)\n",
    "        \n",
    "        y_pred=estimators[n].predict(x_test)\n",
    "        cumulative_y_test=np.concatenate([cumulative_y_test, y_test], 0)\n",
    "        cumulative_y_predict=np.concatenate([cumulative_y_predict, y_pred], 0)\n",
    "\n",
    "    cm = confusion_matrix(cumulative_y_test, cumulative_y_predict, normalize='all') \n",
    "\n",
    "    score=0\n",
    "    \n",
    "    if(flag==0): score=cm.flatten()[2]\n",
    "    else:score=cm.flatten()[1] + 5*cm.flatten()[2] #give more weiight to false negatives\n",
    "    \n",
    "    return score, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2e7c0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running classifiers through Crossvaldiate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3bc01819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runs cross validation trials for a single classifier and parameter\n",
    "# Returns the score and confussion matrix\n",
    "\n",
    "\n",
    "def run_cross(df_bal, classifier, flag, df):\n",
    "\n",
    "    class_key = keys[len(keys) - 1]\n",
    "\n",
    "    y = df_bal[class_key].to_numpy()\n",
    "    x = df_bal.drop(class_key, axis=1).to_numpy()\n",
    "\n",
    "    x_pt, y_pt = calculate_pure_test_values(df, df_bal)\n",
    "\n",
    "    crossed_results = cross_validate(\n",
    "        classifier,\n",
    "        x,\n",
    "        y,\n",
    "        cv=4,\n",
    "        return_train_score=True,\n",
    "        return_estimator=True,\n",
    "        return_indices=True,\n",
    "    )\n",
    "    score, cm = cm_all_runs_crosval(\n",
    "        x,\n",
    "        y,\n",
    "        x_pt,\n",
    "        y_pt,\n",
    "        crossed_results[\"estimator\"],\n",
    "        crossed_results[\"indices\"][\"test\"],\n",
    "        flag,\n",
    "    )\n",
    "\n",
    "    return score, cm\n",
    "\n",
    "\n",
    "# Creates a classifier of the given type with parameter=element of the parameter list\n",
    "# Returns the score and confussion amtrix of the best performing option\n",
    "\n",
    "\n",
    "def run_classifier(\n",
    "    df_bal,\n",
    "    classifier_cons,\n",
    "    classifier_name,\n",
    "    parameter,\n",
    "    flag,\n",
    "    df=None,\n",
    "):\n",
    "    # print(classifier_name)\n",
    "\n",
    "    kw = parameter[0]\n",
    "    dict = {}\n",
    "\n",
    "    for p in parameter[1]:\n",
    "\n",
    "        kwargs = {kw: p}\n",
    "        classifier = classifier_cons(**kwargs)\n",
    "        score, cm = run_cross(df_bal, classifier, flag, df)\n",
    "        dict[score] = [cm, classifier_name, p]\n",
    "\n",
    "    k, v = min(dict), dict[min(dict)]\n",
    "\n",
    "    return k, v\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
